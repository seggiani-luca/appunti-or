
\documentclass[a4paper,11pt]{article}
\usepackage[a4paper, margin=8em]{geometry}

% usa i pacchetti per la scrittura in italiano
\usepackage[french,italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\frenchspacing 

% usa i pacchetti per la formattazione matematica
\usepackage{amsmath, amssymb, amsthm, amsfonts}

% usa altri pacchetti
\usepackage{gensymb}
\usepackage{hyperref}
\usepackage{standalone}

% imposta il titolo
\title{Appunti Ricerca Operativa}
\author{Luca Seggiani}
\date{2024}

% disegni
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}

% imposta lo stile
% usa helvetica
\usepackage[scaled]{helvet}
% usa palatino
\usepackage{palatino}
% usa un font monospazio guardabile
\usepackage{lmodern}

\renewcommand{\rmdefault}{ppl}
\renewcommand{\sfdefault}{phv}
\renewcommand{\ttdefault}{lmtt}

% disponi il titolo
\makeatletter
\renewcommand{\maketitle} {
	\begin{center} 
		\begin{minipage}[t]{.8\textwidth}
			\textsf{\huge\bfseries \@title} 
		\end{minipage}%
		\begin{minipage}[t]{.2\textwidth}
			\raggedleft \vspace{-1.65em}
			\textsf{\small \@author} \vfill
			\textsf{\small \@date}
		\end{minipage}
		\par
	\end{center}

	\thispagestyle{empty}
	\pagestyle{fancy}
}
\makeatother

% disponi teoremi
\usepackage{tcolorbox}
\newtcolorbox[auto counter, number within=section]{theorem}[2][]{%
	colback=blue!10, 
	colframe=blue!40!black, 
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries, 
	title=Teorema~\thetcbcounter: #2, 
	#1
}

% disponi definizioni
\newtcolorbox[auto counter, number within=section]{definition}[2][]{%
	colback=red!10,
	colframe=red!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Definizione~\thetcbcounter: #2,
	#1
}

% disponi problemi
\newtcolorbox[auto counter, number within=section]{problem}[2][]{%
	colback=green!10,
	colframe=green!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Problema~\thetcbcounter: #2,
	#1
}

% disponi codice
\usepackage{listings}
\usepackage[table]{xcolor}

\lstdefinestyle{codestyle}{
		backgroundcolor=\color{black!5}, 
		commentstyle=\color{codegreen},
		keywordstyle=\bfseries\color{magenta},
		numberstyle=\sffamily\tiny\color{black!60},
		stringstyle=\color{green!50!black},
		basicstyle=\ttfamily\footnotesize,
		breakatwhitespace=false,         
		breaklines=true,                 
		captionpos=b,                    
		keepspaces=true,                 
		numbers=left,                    
		numbersep=5pt,                  
		showspaces=false,                
		showstringspaces=false,
		showtabs=false,                  
		tabsize=2
}

\lstdefinestyle{shellstyle}{
		backgroundcolor=\color{black!5}, 
		basicstyle=\ttfamily\footnotesize\color{black}, 
		commentstyle=\color{black}, 
		keywordstyle=\color{black},
		numberstyle=\color{black!5},
		stringstyle=\color{black}, 
		showspaces=false,
		showstringspaces=false, 
		showtabs=false, 
		tabsize=2, 
		numbers=none, 
		breaklines=true
}

\lstdefinelanguage{javascript}{
	keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
	keywordstyle=\color{blue}\bfseries,
	ndkeywords={class, export, boolean, throw, implements, import, this},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{purple}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

% disponi sezioni
\usepackage{titlesec}

\titleformat{\section}
	{\sffamily\Large\bfseries} 
	{\thesection}{1em}{} 
\titleformat{\subsection}
	{\sffamily\large\bfseries}   
	{\thesubsection}{1em}{} 
\titleformat{\subsubsection}
	{\sffamily\normalsize\bfseries} 
	{\thesubsubsection}{1em}{}

% disponi alberi
\usepackage{forest}

\forestset{
	rectstyle/.style={
		for tree={rectangle,draw,font=\large\sffamily}
	},
	roundstyle/.style={
		for tree={circle,draw,font=\large}
	}
}

% disponi algoritmi
\usepackage{algorithm}
\usepackage{algorithmic}
\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\makeatother

% disponi numeri di pagina
\usepackage{fancyhdr}
\fancyhf{} 
\fancyfoot[L]{\sffamily{\thepage}}

\makeatletter
\fancyhead[L]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@title \ \@date}}} 
\fancyhead[R]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@author}}}
\makeatother

\begin{document}

% sezione (data)
\section{Lezione del 26-09-24}

% stili pagina
\thispagestyle{empty}
\pagestyle{fancy}

% testo
\subsection{Geometria dei poliedri}
Introduciamo progressivamente i tipi di \textbf{combinazione} che ci sono utili nello studio dei problemi di programmazione lineare.

\subsubsection{Combinazioni lineari}
\begin{definition}{Combinazione lineare}
	Dati $ x_1, x_2, ..., x_k \in \mathbb{R}^n $ punti, $y$ si dice \textbf{combinazione lineare} di $ x_1, x_2, ..., x_k $ se:
	$$
	\exists \lambda_i \quad (i = 1, ..., k) \quad \text{t.c.} \quad y = \sum_{i=1}^k \lambda_i x_i 
	$$
\end{definition}

Le combinazioni lineari sono utili per esprimere la funzione obiettiva sulla base dei vettori costo, ma non bastano a trovarne una soluzione ottimale.

\subsubsection{Combinazioni convesse}
Si introduce quindi il concetto di:
\begin{definition}{Combinazione convessa}
	Dati $ x_1, x_2, ..., x_k \in \mathbb{R}^n $ punti, $y$ si dice \textbf{combinazione convessa} di $ x_1, x_2, ..., x_k $ se:
	$$
	\exists \lambda_i \in [0, 1] \quad (i = 1, ..., k), \quad \sum_{i=1}^k \lambda_i = 1 \quad \text{t.c.} \quad y = \sum_{i=1}^k \lambda_i x_i 
	$$
\end{definition}

Possiamo dare un esempio di cos'è la combinazione convessa di due punti in $\mathbb{R}^2$.
Posti $x_1$ e $x_2$, si ha:
$$
\lambda_1 + \lambda_2 = 1 \Rightarrow \lambda_2 = (1 - \lambda_1), \quad y = \lambda x_1 + (1 - \lambda ) x_2, \quad \lambda \in [0, 1]
$$
che riconosciamo essere l'equazione di un segmento $\bar{x_1x_2}$ (primo grafico).

Possiamo provare con tre punti: si avrà:
$$
y = \lambda_1 x_1 + \lambda_2 x_2 + \lambda_3 x_3, \quad \lambda_1 + \lambda_2 + \lambda_3 = 1, \quad \lambda_i \in [0, 1]
$$
che si riconduce all'equazione del triangolo di vertici $x_1$, $x_2$, $x_3$ (secondo grafico).
\par\medskip

\begin{minipage}{0.45\textwidth}
    % Segment on a graph
	\begin{tikzpicture}[scale=0.75]
    \begin{axis}[
        axis lines = center,
        xlabel = $x$, ylabel = $y$,
        xmin= -0.8, xmax=4.8, ymin=-0.8, ymax=4.8,
        grid = minor,
				title = {Combinazione di $x_1$ e $x_2$}
    ]
        \addplot[thick] coordinates {(1,2) (4,2)};
        \addplot[only marks, mark=*] coordinates {(1,2)} node[anchor=north] {$x_1$};
        \addplot[only marks, mark=*] coordinates {(4,2)} node[anchor=north] {$x_2$};
    \end{axis}
    \end{tikzpicture}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
    % Triangle on a graph
    \begin{tikzpicture}[scale=0.75]
    \begin{axis}[
        axis lines = center,
        xlabel = $x$, ylabel = $y$,
        xmin= -0.8, xmax=4.8, ymin=-0.8, ymax=4.8,
        grid = minor,
				title = {Combinazione di $x_1$, $x_2$ e $x_3$}
    ]
        \addplot[thick] coordinates {(1,1) (4,1) (2,3) (1,1)};
        \addplot[only marks, mark=*] coordinates {(1,1)} node[anchor=north] {$x_1$};
        \addplot[only marks, mark=*] coordinates {(4,1)} node[anchor=north] {$x_2$};
        \addplot[only marks, mark=*] coordinates {(2,3)} node[anchor=south] {$x_3$};
    \end{axis}
    \end{tikzpicture}
\end{minipage}
\par\medskip

Dai grafici si nota come una combinazione convessa descrive una parte di spazio, che si può definire:
\begin{definition}{Involucro convesso}
	L'involucro convesso $\mathrm{conv}(K)$ di un'insieme di punti $K = \{x_1, x_2, ..., x_n\}, \quad x_i \in \mathbb{R}^n$ è definito come il luogo di tutte le loro combinazioni convesse.
\end{definition}

Si nota che l'involucro convesso negli esempi precedenti è effettivamente un poliedro convesso che contiene tutti i punti che lo formano.
Si può infatti dire:
\begin{theorem}{Minimalità dell'involucro convesso}
	L'insieme $\mathrm{conv}(K)$ di tutte le combinazioni convesse di $n$ punti è l'insieme convesso minimale che li contiene tutti.
\end{theorem}

In $R^n$, possiamo esprimere un insieme convesso lineare come un poliedro convesso, e quindi dire che l'involucro convesso di $n$ punti è il più piccolo (in termini di inclusione) poliedro convesso che li contiene tutti.
Inoltre, un'insieme è convesso se e solo se corrisponde al suo involucro convesso.

Si noti che non è detto che a $n$ punti corrisponda un poligono di $n$ vertici.
Potrebbe infatti accadere che uno dei punti (chiamiamolo $x_j$) sia già parte dell'involucro convesso, ergo $x_j \in \mathrm{conv}(K)$.

Le combinazioni convesse ci permettono di descrivere parte delle regioni ammissibili (poliedri) dei problemi di programmazione lineare, ma restano ancora in sospeso problemi che ammettono regioni illimitate.
Per descrivere tali regioni, si introduce un altro tipo di combinazione.

\subsubsection{Combinazioni coniche}
\begin{definition}{Combinazione conica}
	Dati $ x_1, x_2, ..., x_k \in \mathbb{R}^n $ punti, $y$ si dice \textbf{combinazione conica} di $ x_1, x_2, ..., x_k $ se:
	$$
	\exists \lambda_i \geq 0 \quad (i = 1, ..., k) \quad \text{t.c.} \quad y = \sum_{i=1}^k \lambda_i x_i 
	$$
\end{definition}

La combinazione conica di più punti non è più il poliedro convesso che li contiene, ma il cono con vertice nell'origine, convesso o meno, che li contiene, definito come:
\begin{definition}{Involucro conico}
	L'involucro conico $\mathrm{cono}(K)$ di un'insieme di punti $K = \{x_1, x_2, ..., x_n\} \in \mathbb{R}^n$ è definito come il luogo di tutte le loro combinazioni coniche.
\end{definition}

Questo cono si estende fino all'infinito ($\lambda_i \geq 0$) nelle direzioni dei vettori che lo formano.
Il concetto è simile a quello di spazio somma, ma con la differenza che non si va ovunque nello span dei due vettori, ma si seguono le semirette che essi conducono.

Si può dire, analogamente alle combinazioni convesse, che il cono di $n$ punti è il pi+ piccolo (in termini di inclusione) cono convesso che li contiene.
Inoltre, un'insieme è un cono convesso se e solo se corrisponde al suo involucro conico.

\subsection{Poliedri}
Abbiamo definito un poliedro come la regione definita da un sistema di disequazioni lineari, o geometricamente come l'intersezione di un numero finito di semipiani chiusi in $\mathbb{R}^n$.
Si dimostra che un poliedro, in quanto intersezione di insiemi convessi, è lui stesso convesso: potremo applicare la definizione di convessità per dire che, presi due punti $x_1, x_2 \in C$ nell'intersezione $C = C_1 \cap C_2$, si avrà che entrambi appartengono sia a $C_1$ che a $C_2$, ergo il segmento che li congiunge completamente in ciascuno di quei due insiemi è interamente contenuto in $C$.

Un poliedro che è anche cono si chiama cono poliedrico. Si dimostra che:
\begin{theorem}{Cono poliedrico}
	Se $P$ è un cono poliedrico allora:
	$$
	\exists Q \quad \text{t.c.} \quad P = \{ x \in \mathbb{R}^n : Qx \leq 0 \}
	$$
	con $Q$ matrice.
\end{theorem}

Senza dimostrazioni, questo è chiaro dal fatto che le disequazioni che compongono il poliedrico sono omogenee (hanno frontiere che passano dall'origine).

Si definiscono poi i \textbf{vertici} del poliedro:
\begin{definition}{Vertice}
	Un vertice di un poliedro è un punto che non si può esprimere come combinazione convessa propria di altri punti del poliedro.
	Si indica l'insieme dei vettori di un poliedro $P$ come $\mathrm{vert}(P)$.
\end{definition}
Notiamo che i vertici di un poliedro limitato corrispondono ai punti che formano la combinazione convessa equivalente al poliedro.
Per poliedri illimitati, introduciamo invece:
\begin{definition}{Direzione di recessione}
	Un vettore $d$ è la direzione di recessione di un poliedro se:
	$$
	x + \lambda d \in P \quad \forall x \in P, \quad \forall \lambda \geq 0
	$$
	Si indica come $\mathrm{rec}(P)$ l'insieme delle direzioni di recessione di un poliedro.
\end{definition}

Chiaramente, per ogni poliedro $P$, $0 \in \mathrm{rec}(P)$ e per i poliedri limitati, $\mathrm{rec}(P) = \{0\}$.
Notiamo che le direzioni di recessione determinano i vettori del cono che coincide (almeno a distanze abbastanza grandi dall'origine) con i poliedri illimitati.

Inoltre, l'insieme $\mathrm{rec}(p)$ di un poliedro è in sé un cono poliedrico. In particolare: 

\begin{theorem}{Cono di recessione}	
Il cono di recessione di un poliedro $P$ è dato da:
$$
P = \{ x \in \mathbb{R}^n : Ax \leq b \} \Rightarrow \mathrm{rec}(P) = \{ x \in \mathbb{R}^n : Ax \leq 0 \}
$$
\end{theorem}

\par\medskip
\noindent
\textbf{\textsf{Dimostrazione}} \\
Questo teorema vale perchè, per definizione, una direzione di recessione è $x + \lambda d$, che sostituita al sistema dà:
$$
A(x + \lambda d) \leq b \Rightarrow Ax + \lambda Ad \leq b
$$

Possiamo quindi sottrarre $Ax$ da entrambi i lati:
$$
\lambda Ad \leq b - Ax
$$

Da ipotesi, $Ax \leq b$ e quindi $b - Ax \geq 0$.
Chiamiamo questa quantità postiva $k^+$ e scriviamo:
$$
\lambda Ad \leq k^+
$$

Visto che $\lambda \rightarrow +\infty$, dovrà essere verò che $Ad \leq 0$, ergo con $d = x$, il teorema è dimostrato.

\par\medskip

Un'altro teorema importante lega il cono ai suoi "raggi estremi", cioè quell'insieme finito di vettori la cui combinazione conica corrisponde all'intero cono:
\begin{theorem}{Raggi estremi}
	Un cono poliedrico $P = \{ x \in \mathbb{R^n} : Ax \leq 0 \}$ è l'involucro conico di un'insieme limitato dei suoi punti. Questi punti prendono il nome di \textit{raggi estremi}.
\end{theorem}

\par\medskip
\noindent
\textbf{\textsf{Dimostrazione}} \\
Diamo una dimostrazione più o meno intuitiva di questo risultato.
Indichiamo con $A_1, ..., A_m$ le righe della matrice $A$. 
Queste formeranno dei vettori che indicano la direzione su cui "agisce" la diseguaglianza.
Si può semplicemente osservare che questi vettori sono perpendicolari agli estremi del cono.
Prendiamo quindi il cono dei vettori, che formerà un'altro cono detto \textit{duale} del cono di partenza:
$$
\mathrm{cono}(A_1, ..., A_m) = \{ x \in \mathbb{R}^n : Qx \leq 0 \}
$$

I vettori $Q_1, ..., Q_t$, presi come righe della matrice, sono perpendicolari ai vettori $A_1, ..., A_n$ di partenza, ergo paralleli ai raggi estremi del cono di partenza.
Possiamo quindi dire che:
$$
P = \mathrm{cono}(Q_1, ..., Q_t)
$$

\subsubsection{Spazio di linealità}

Definiamo infine lo spazio di linealità:
\begin{definition}{Spazio di linealità}
	Lo spazio di linealità di un poliedro illimitato $P$ è il più piccolo sottospazio contenuto interamente in $P$.
\end{definition}
Ogni vettore di base di uno spazio di linealità è un vettore $d$ tale che:
$$
d \in \mathrm{rec}(P), \quad - d \in \mathrm{rec}(P)
$$
ovvero un vettore che è contenuto sia positivo che negativo nelle direzioni di recessione del poliedro.

Questa distinzione è importante in quanto non si può dimostrare completamente il prossimo teorema su poliedri con spazio di linealità $\neq {0}$.

\subsubsection{Teorema di rappresentazione dei poliedri}
Gli strumenti che abbiamo stabilito finora ci permettono di enunciare un'importante risultato, noto come \textbf{teorema di rappresentazione dei poliedri}, o teorema di Minkowski-Weyl.

\begin{theorem}{Rappresentazione dei poliedri}
	Dato un poliedro $P$ definito come $P = \{ x \in \mathbb{R}^n : Ax \leq b \}$, si ha:
	$$
	\exists V = \{ v_1, ..., v_k \} \in \mathrm{vert}(P), \quad \exists E = {e_1, ..., e_p} \in \mathrm{rec}(P) \quad \text{t.c.} \quad P = \mathrm{conv}(V) + \mathrm{cono}(E)
	$$
\end{theorem}

Questo significa che è possibile rappresentare qualsiasi poliedro attraverso i suoi vertici, e le direzioni in cui si estende all'infinito (ergo le sue direzioni di recessione).

\subsubsection{H-rappresentazioni e V-rappresentazioni}
Possiamo intendere il risultato precedente come segue: per ogni poliedro di un problema di programmazione LP, abbiamo due possibili rappresentazioni:
\begin{itemize}
	\item \textbf{H-rappresentazione:} come intersezione di semispazi, ergo come insieme delle soluzioni di un sistema di disequazioni lineari.
	\item \textbf{V-rappresentazione:} come un'insieme di vertici e direzioni di regressione, quindi un involucro convesso e un cono di regressione.
\end{itemize}

\par\smallskip

Non diamo una dimostrazione del teorema ma possiamo, noti i concetti di H-rappresentazione e V-rappresentazione, dire che:
\begin{itemize}
	\item Da un \textbf{H-rappresentazione} si può ricavare una \textbf{V-rappresentazione}:
		abbiamo un poliedro dato dall'H-rappresentazione $Ax \leq b$.
		Dividiamo questo poliedro in una parte limitata e una parte illimitata: la parte limitata sarà data dai vertici, mentre la parte illimitata sarà data dal cono di regressione:
		$$ P = \mathrm{conv}(v_1,...,v_k) + rec(P)$$
		A questo punto possiamo esprimere, come dallo scorso lemma, come combinazione conica dei suoi raggi estremi:
		$$ P = \mathrm{conv}(v_1, ..., v_k) + \mathrm{cono}(e_1, ..., e_p) $$

	\item Da un \textbf{V-rappresentazione} si può ricavare una \textbf{H-rappresentazione}:
		abbiamo un poliedro dato dalla V-rappresentazione $P = \mathrm{conv}(v_1, ..., v_k) + \mathrm{cone}(e_1, ..., e_p)$.
		Prendiamo separatamente gli involucri convessi e conici: avremo che per l'involucro convesso possiamo immediatamente riportare in una forma ad intersezione di semipiani (disequazioni):
		$$ \mathrm{conv}(v_1, ..., v_k) = \{ x \in \mathbb{R}^n : A'x \leq b' \} $$
		mentre per l'involucro conico possiamo portare in una forma ad intersezione di disequazioni omogenee:
		$$ \mathrm{cone}(e_1, ..., e_p) = \{ x \in \mathbb{R}^n : A''x \leq 0 \} $$
		Per trovare l'H-rappresentazione, basterà combinare queste due rappresentazioni in una forma del tipo:
		$$ P = \{ x \in \mathbb{R}^n : A'x \leq b', A''x \leq 0 \}$$
\end{itemize}

La somma in $P = \mathrm{conv}(V) + \mathrm{cono}(E)$ si riferisce alla somma vettoriale fra tutti i possibili punti di $\mathrm{conv}(V)$ e $\mathrm{conv}(E)$, come quella studiata sui sottospazi vettoriali (anche se nessuno dei due insiemi è un sottospazio vettoriale).
Per un dato insieme $\mathrm{conv}(V)$, quindi, l'aggiunta di $\mathrm{cono}(E)$ rappresenta la "proiezione" di tale insieme nelle direzioni di recessione indicate dal cono.

Più propriamente, posto $\mathrm{lineal}(P) = {0}$, si ha:

\begin{theorem}{Rappresentazione dei poliedri non lineali}
	Dato un poliedro $P$ definito come $P = \{ x \in \mathbb{R}^n : Ax \leq b \}$, tale che $\mathrm{lineal}(P)$, si ha:
	$$
	P = \mathrm{conv}(\mathrm{vert}(P)) + \mathrm{rec}(P)
	$$
\end{theorem}
la limitazione di linealità è necessaria in quanto un poliedro lineale potrebbe non essere rappresentato, nelle sue dimensioni infinite, dal semplice insieme dei suoi vettori.
In verità, è possibile dimostrare che:

\begin{theorem}{Linealità di poliedri}
	Per ogni poliedro $P$ non vuoto si ha:
	$$
		\mathrm{vert}(P) \neq \emptyset \Leftrightarrow \mathrm{lineal}(P) = {0}
	$$
\end{theorem}
ergo applicando lo scorso teorema potremmo provare a rappresentare un poliedro attraverso un'insieme di vettori vuoto.

Per i poliedri che otteniamo dai problemi di programmazione lineare, però, abbiamo i corollari:
\begin{itemize}
	\item Un poliedro limitato è l'involucro convesso dei suoi vertici;
	\item Se il poliedro ha vincoli di positività sulle sue variabili, allora non è lineale, ergo si applica il teorema di rappresentazione.
		Questo è il tipo di poliedri a cui siamo abituati.
\end{itemize}

\subsection{Teorema fondamentale della PL}
Quanto riportare finora sulla geometria dei poliedri può essere usato per dimostrare il seguente teorema:
\begin{theorem}{Teorema fondamentale della PL}
	Sia dato un poliedro $P$ rappresentato come:
	$$ 
	P = \mathrm{conv}(V) + \mathrm{cono}(E), \quad V = \{ v_1, ..., v_k \}, \quad E = \{ e_1, ..., e_p \}
	$$
	Se il problema $\mathcal{P}$ con regione ammissibile $P$ ha valore ottimo finito, allora esiste $s \in \{ 1, ..., k \}$ tale che $v_k$ è soluzione ottima di $\mathcal{P}$.
\end{theorem}

In sostanza, se un problema LP ha soluzione, essa si trova su uno dei vertici del poliedro della regione ammissibile.

\par\medskip
\noindent
\textbf{\textsf{Dimostrazione}} \\
Sia dato un problema LP $\mathcal{P}$ in forma primale standard, ergo posto come:
\[
	\begin{cases}
		\max{c^\intercal \cdot x} \\ 
		Ax \leq b	
	\end{cases}
\]
ergo con regione ammissibile rappresentata da un poliedro $P$.

Dal teorema della rappresentazione, possiamo esprimere il poliedro come:
$$
	P = \mathrm{conv}(V) + \mathrm{cono}(E), \quad V = \{ v_1, ..., v_k \}, \quad E = \{ e_1, ..., e_p \}
$$

Combiniamo le due equazioni, ergo esprimiamo prima il punto $\bar{x}$ generico del poliedro applicando le definizioni di involucro convesso e conico:
$$
\bar{x} \in P : P = \mathrm{conv}(V) + \mathrm{cono}(E), \quad \bar{x} = \sum_{i=1}^k \lambda_i v_i + \sum_{j=i}^p \mu_j e_j
$$
ed esprimiamo quindi la funzione obiettivo come il prodotto scalare fra il vettore costo e il punto $\bar{x}$ del poliedro:
$$
c^\intercal \cdot \bar{x} = c^\intercal \cdot \left( \sum_{i=1}^k \lambda_i v_i + \sum_{j=i}^p \mu_j e_j \right) = \sum_{i=1}^k \lambda_i c^\intercal v_i + \sum_{j=i}^p \mu_j c^\intercal e_j
$$

A questo punto conviene chiarire su cosa significa che il problema ha valore ottimo finito.
Il secondo termine è la combinazione conica della sommatoria dei vettori di recessione scalati dal vettore costo.
Se almeno uno dei $c^\intercal e_j > 0$, si avrà che portando $\mu_j \rightarrow +\infty$ la funzione avrà massimo $= \infty$.
Geometricamente, questo significa che esiste una direzione illimitata del poliedro dove i vettori costo permettono alla funzione di crescere all'infinito.

Dunque sarà vero che $c^\intercal e_j \leq 0 \quad \forall j \in \{ 1, ..., p \}$ se vogliamo che la funzione abbia valore ottimo finito.

Possiamo quindi usare questa ipotesi per dire:
$$
c^\intercal \cdot \bar{x} = \sum_{i=1}^k \lambda_i c^\intercal v_i + \sum_{j=i}^p \mu_j c^\intercal e_j \leq \sum_{i=1}^k \lambda_i c^\intercal v_i \leq \sum_{i=1}^k \max_{1 \leq i \leq p} \left(\lambda_i c^\intercal v_i\right) 
$$

$$
= \left( \max_{1 \leq i \leq p} c^\intercal v_i\right) \sum_{i=1}^k \lambda_i = \max_{1\leq i \leq p} c^\intercal v_i = c^\intercal v_k
$$

E quindi $\max_{x \in P} c^\intercal \cdot x \leq c^\intercal v_k$.
A questo punto, visto che $\bar{x}$ è effettivamente un punto della regione ammissibile, sarà vero che:
$$
c^\intercal v_k \leq \max_{x \in P} c^\intercal \cdot x
$$

E dunque $\max_{x \in P} c^\intercal \cdot x = c^\intercal v_k$, come volevasi dimostrare. 

\end{document}
